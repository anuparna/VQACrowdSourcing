
# Let's Agree to Disagree - A Crowdsourcing experiment to understand disagreement among answers to Visual Questions

In the realm of Visual Question Answering, some questions might have multiple answers from crowd-workers. 
This project is an attempt to learn about the disagreements among crowd-workers in answering a question based on an image.

## Dataset
A crowd-sourcing experiment was conducted on **Amazon Mechanical Turk** with a sample of 144 images (48 each) from *VQA Real Dataset, VQA Abstract Scenes dataset and VizWiz dataset*.

## Setup

